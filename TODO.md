# TODO LIST
1. Start character positions from 1 instead of 0 when tokenizing
2. Implement lexer to read each token and categorize what it is
